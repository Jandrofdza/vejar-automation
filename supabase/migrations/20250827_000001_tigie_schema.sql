-- enums
create type review_status as enum ('new','processing','classified','needs_review','approved','failed');

-- core tables
create table if not exists submissions (
  id uuid primary key default gen_random_uuid(),
  requ_id text,                 
  nombre_corto text not null,
  descripcion text,
  created_by uuid not null default '00000000-0000-0000-0000-000000000000',
  status review_status not null default 'new',
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now()
);

create table if not exists files (
  id uuid primary key default gen_random_uuid(),
  submission_id uuid not null references submissions(id) on delete cascade,
  storage_path text not null,
  mime_type text,
  size_bytes bigint,
  sha256 text,
  kind text check (kind in ('image','pdf','other')),
  page_count int,
  uploaded_by uuid not null default '00000000-0000-0000-0000-000000000000',
  created_at timestamptz not null default now()
);

create table if not exists classifications (
  id uuid primary key default gen_random_uuid(),
  submission_id uuid not null references submissions(id) on delete cascade,
  model_name text,
  prompt_version text,
  fraccion text not null,
  justificacion text not null,
  arbol jsonb,
  alternativas jsonb,
  dudas_cliente text,
  regulacion text,
  notas_clasificador text,
  confidence numeric,
  final boolean not null default false,
  created_at timestamptz not null default now(),
  created_by uuid
);

create table if not exists reports (
  id uuid primary key default gen_random_uuid(),
  submission_id uuid not null references submissions(id) on delete cascade,
  storage_path text not null,
  created_at timestamptz not null default now()
);

create table if not exists jobs (
  id bigint generated by default as identity primary key,
  submission_id uuid not null references submissions(id) on delete cascade,
  status text not null default 'queued', -- queued|running|done|failed
  attempts int not null default 0,
  last_error text,
  run_at timestamptz not null default now(),
  locked_at timestamptz,
  created_at timestamptz not null default now()
);

create table if not exists audit_events (
  id bigint generated by default as identity primary key,
  actor uuid, event text, meta jsonb, created_at timestamptz default now()
);

-- RLS
alter table submissions enable row level security;
alter table files enable row level security;
alter table classifications enable row level security;
alter table reports enable row level security;
alter table jobs enable row level security;

-- simple ownership (v1: system-owned; reads allowed to owner-only when you add auth)
create policy p_submissions_read on submissions for select using (true);
create policy p_files_read on files for select using (
  exists(select 1 from submissions s where s.id = files.submission_id)
);
create policy p_cls_read on classifications for select using (
  exists(select 1 from submissions s where s.id = classifications.submission_id)
);
create policy p_reports_read on reports for select using (
  exists(select 1 from submissions s where s.id = reports.submission_id)
);
create policy p_jobs_read on jobs for select using (
  exists(select 1 from submissions s where s.id = jobs.submission_id)
);

-- buckets (private)
select storage.create_bucket('submissions', false, false);
select storage.create_bucket('reports', false, false);

-- job locker
create or replace function lock_next_job()
returns table(id bigint, submission_id uuid) language plpgsql as $$
begin
  return query
  with j as (
    select * from jobs
    where status = 'queued' and (run_at <= now())
    order by created_at asc
    for update skip locked limit 1
  )
  update jobs set status='running', attempts=attempts+1, locked_at=now()
  from j where jobs.id = j.id
  returning jobs.id, jobs.submission_id;
end; $$;
